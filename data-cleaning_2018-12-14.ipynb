{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV file cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import some packages for cleaning, plotting, and transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import json\n",
    "import pathlib\n",
    "import re\n",
    "from typing import NamedTuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the path to the CSV data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('data/daily/csvs')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = pathlib.Path('data/daily/csvs')\n",
    "data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a test path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('data/daily/csvs/dly1616.csv')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fname = 'dly1616.csv'\n",
    "test_fpath = data_path / test_fname\n",
    "test_fpath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the first 20 lines of the test file to get a sense of the structure of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station Name: COOLGREANEY (St.Martins)\r\n",
      "Station Height: 67 M \r\n",
      "Latitude:52.760  ,Longitude: -6.239\r\n",
      "\r\n",
      "\r\n",
      "date:  -  09 to 09 utc\r\n",
      "rain:  -  Precipitation Amount (mm)\r\n",
      "ind:   -  Indicator\r\n",
      "\r\n",
      "date,ind,rain\r\n",
      "01-apr-2003,0,0.200\r\n",
      "02-apr-2003,0,0.000\r\n",
      "03-apr-2003,0,0.000\r\n",
      "04-apr-2003,0,0.000\r\n",
      "05-apr-2003,0,0.000\r\n",
      "06-apr-2003,0,0.000\r\n",
      "07-apr-2003,0,0.000\r\n",
      "08-apr-2003,0,0.000\r\n",
      "09-apr-2003,0,0.000\r\n",
      "10-apr-2003,0,0.000\r\n"
     ]
    }
   ],
   "source": [
    "!head -n20 'data/daily/csvs/dly1616.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip the irrelevant rows, and call `.head()` on the `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ind</th>\n",
       "      <th>rain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-apr-2003</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02-apr-2003</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03-apr-2003</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04-apr-2003</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05-apr-2003</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  ind  rain\n",
       "0  01-apr-2003    0   0.2\n",
       "1  02-apr-2003    0   0.0\n",
       "2  03-apr-2003    0   0.0\n",
       "3  04-apr-2003    0   0.0\n",
       "4  05-apr-2003    0   0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(test_fpath, skiprows=9)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dly10023.csv:10\r\n",
      "dly1024.csv:10\r\n",
      "dly1033.csv:10\r\n",
      "dly1042.csv:10\r\n",
      "dly1043.csv:10\r\n"
     ]
    }
   ],
   "source": [
    "!head -n5 'data/header_rows.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FilenameHeaderLine(filename='dly10023.csv', line_num=10),\n",
       " FilenameHeaderLine(filename='dly1024.csv', line_num=10)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FilenameHeaderLine(NamedTuple):\n",
    "    filename: str\n",
    "    line_num: int\n",
    "\n",
    "with open('data/header_rows.txt', 'rt') as f:\n",
    "    # create a list of tuples of (filename, header_line_num)\n",
    "    fname_headerline = [tuple(line.strip().split(':')) for line in f]\n",
    "    \n",
    "    # turn this list of tuples into a list of NamedTuples\n",
    "    header_starts = [\n",
    "        FilenameHeaderLine(filename=fname, line_num=int(line_num))\n",
    "        for fname, line_num in fname_headerline\n",
    "    ]\n",
    "\n",
    "header_starts[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StationDetails(id=2115, name='HACKETSTOWN_(Voc.Sch.)', county='Carlow', lat=52.857, lon=-6.552),\n",
       " StationDetails(id=375, name='Oak_Park', county='Carlow', lat=52.857, lon=-6.909)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class StationDetails(NamedTuple):\n",
    "    id: int\n",
    "    name: str\n",
    "    county: str\n",
    "    lat: float\n",
    "    lon: float\n",
    "\n",
    "with open('data/stations_clean.csv', 'rt') as f:\n",
    "    csv_reader = csv.reader(f)\n",
    "\n",
    "    # skip the header\n",
    "    next(csv_reader)\n",
    "    \n",
    "    # create a list of NamedTuples with the details for each station\n",
    "    details = [\n",
    "        StationDetails(\n",
    "            id=int(id),\n",
    "            name=name,\n",
    "            county=county,\n",
    "            lat=float(lat),\n",
    "            lon=float(lon),\n",
    "        )\n",
    "        for id, name, county, lat, lon in csv_reader\n",
    "    ]\n",
    "\n",
    "details[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to combine the station details with the information about the header lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the two structures are of different length.\n",
    "The `details` structure contains details for stations for which data wasn't available.\n",
    "Create a blacklist, which ignores these stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518\n",
      "498\n"
     ]
    }
   ],
   "source": [
    "print(len(details))\n",
    "print(len(header_starts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3422, 9938]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these files can be identified by running the following command\n",
    "# in the directory containing all of the downloaded zip files\n",
    "# $ find . -type f -size -1024c\n",
    "blacklist_string = \"\"\"\n",
    "./dly3422.zip\n",
    "./dly9938.zip\n",
    "./dly2931.zip\n",
    "./dly538.zip\n",
    "./dly9323.zip\n",
    "./dly4413.zip\n",
    "./dly3037.zip\n",
    "./dly1807.zip\n",
    "./dly4702.zip\n",
    "./dly2604.zip\n",
    "./dly199.zip\n",
    "./dly5819.zip\n",
    "./dly5602.zip\n",
    "./dly9206.zip\n",
    "./dly8912.zip\n",
    "./dly2218.zip\n",
    "./dly8123.zip\n",
    "./dly5729.zip\n",
    "./dly9106.zip\n",
    "./dly907.zip\n",
    "\"\"\"\n",
    "# create a list of station numbers as ints\n",
    "blacklist = [int(line[5:-4]) for line in blacklist_string.split()]\n",
    "blacklist[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StationFileDetails(id=2115, name='HACKETSTOWN_(Voc.Sch.)', county='Carlow', lat=52.857, lon=-6.552, fname='dly2115.csv', header_line_num=10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class StationFileDetails(NamedTuple):\n",
    "    id: int\n",
    "    name: str\n",
    "    county: str\n",
    "    lat: float\n",
    "    lon: float\n",
    "    fname: str\n",
    "    header_line_num: int\n",
    "\n",
    "# create a mapping from station number to filename and header line number\n",
    "station_num_header_starts = {\n",
    "    # extract station numbers from files in the form dly9106.csv\n",
    "    int(re.match(r'dly(\\d+)\\.csv', fn_header_line.filename).group(1)): fn_header_line\n",
    "    for fn_header_line in header_starts\n",
    "}\n",
    "\n",
    "station_and_file_details = []\n",
    "\n",
    "for detail in details:\n",
    "    # we're only interested in the `id` once we unpack `detail`\n",
    "    station_id, *_ = detail\n",
    "    \n",
    "    # if `id` is in the blacklist then skip this record\n",
    "    if station_id in blacklist:\n",
    "        continue\n",
    "    \n",
    "    # otherwise, create a new super-structure with all\n",
    "    # of the details\n",
    "    d = StationFileDetails(\n",
    "        *detail,\n",
    "        *station_num_header_starts[station_id],\n",
    "    )\n",
    "    station_and_file_details.append(d)\n",
    "\n",
    "station_and_file_details[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to JSON\n",
    "\n",
    "We now want to export the data structure (`station_and_file_details`) to JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 839,\n",
       " 'station': 'EMYVALE',\n",
       " 'filename': 'dly839.csv',\n",
       " 'lat': 54.338,\n",
       " 'lon': -6.956,\n",
       " 'header_line_num': 10}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by_county = defaultdict(list)\n",
    "\n",
    "for detail in station_and_file_details:\n",
    "    d = {\n",
    "        'id': detail.id,\n",
    "        'station': detail.name,\n",
    "        'filename': detail.fname,\n",
    "        'lat': detail.lat,\n",
    "        'lon': detail.lon,\n",
    "        'header_line_num': detail.header_line_num,\n",
    "    }\n",
    "\n",
    "    by_county[detail.county].append(d)\n",
    "\n",
    "by_county['Monaghan'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/stations.json', 'wt') as f:\n",
    "    json.dump(by_county, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
